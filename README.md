# Movies-ETL
This repository was created as part of a 6 month Data Analystics Bootcamp administed by George Washington University. This is the repository for the Module 7 Challenge. This challenge consolidated the topics from previous challenges and asked us to extract, transform, and load large datasets into a postgreSQL database.. Topics covered including cleaning datasets, merging datasets, writing regular expressions, and loading a pandas DataFrame into postgreSQL. Final project work is in Movies_ETL.ipynb. 

## Summary
The purpose of this assignment was to practice the extract, transform, load process with two large publicly available datasets. Two datasets of movie information were sourced from Kaggle and Wikipedia. Python and pandas were used to clean and merge the datasets. The final dataset was then loaded into a local postgreSQL database. 

This assignment helped tie together a lot of the topics we had been learning up until this point. I found using pandas to view and work with the data was becoming very natural. I used regular expressions to clean up the box office numbers, and learning about them was the biggest challenge of the assignment. I am much more comfortable with using regex now and excited to apply this knowledge to other projects. 

Example of functions used to clean data. 
![Cleaning Example](/Resources/cleaning_example.PNG)


Verifying the cleaned DataFrame was loaded into postgreSQL
![Verifying the data was loaded](/Resources/movies_query.PNG)

